{1: {'SSE': 46267149809.610176, 'correct_pred': 996, 'classification_report': '              precision    recall  f1-score   support\n\n           0       0.11      0.38      0.16       971\n           1       0.00      0.00      0.00       963\n           2       0.11      0.20      0.14       986\n           3       0.09      0.05      0.06       973\n           4       0.11      0.03      0.05       991\n           5       0.10      0.24      0.14       979\n           6       0.10      0.12      0.11       971\n           7       0.00      0.00      0.00       996\n           8       0.14      0.00      0.00       986\n           9       0.00      0.00      0.00      1000\n\n    accuracy                           0.10      9816\n   macro avg       0.07      0.10      0.07      9816\nweighted avg       0.07      0.10      0.07      9816\n'}, 6: {'SSE': 31829562071.01058, 'correct_pred': 3290, 'classification_report': '              precision    recall  f1-score   support\n\n           0       0.25      0.26      0.26       971\n           1       0.47      0.55      0.51       963\n           2       0.26      0.19      0.22       986\n           3       0.25      0.31      0.28       973\n           4       0.20      0.19      0.19       991\n           5       0.43      0.51      0.47       979\n           6       0.17      0.10      0.12       971\n           7       0.39      0.41      0.40       996\n           8       0.35      0.34      0.34       986\n           9       0.44      0.49      0.46      1000\n\n    accuracy                           0.34      9816\n   macro avg       0.32      0.34      0.33      9816\nweighted avg       0.32      0.34      0.33      9816\n'}, 11: {'SSE': 27606584066.064022, 'correct_pred': 4164, 'classification_report': '              precision    recall  f1-score   support\n\n           0       0.39      0.42      0.41       971\n           1       0.49      0.75      0.59       963\n           2       0.30      0.35      0.32       986\n           3       0.28      0.24      0.26       973\n           4       0.32      0.30      0.31       991\n           5       0.49      0.55      0.52       979\n           6       0.25      0.12      0.16       971\n           7       0.51      0.44      0.47       996\n           8       0.42      0.41      0.41       986\n           9       0.66      0.66      0.66      1000\n\n    accuracy                           0.42      9816\n   macro avg       0.41      0.42      0.41      9816\nweighted avg       0.41      0.42      0.41      9816\n'}, 16: {'SSE': 25324018447.12288, 'correct_pred': 4885, 'classification_report': '              precision    recall  f1-score   support\n\n           0       0.46      0.47      0.46       971\n           1       0.66      0.77      0.71       963\n           2       0.34      0.37      0.35       986\n           3       0.41      0.43      0.42       973\n           4       0.36      0.34      0.35       991\n           5       0.52      0.61      0.56       979\n           6       0.27      0.13      0.18       971\n           7       0.58      0.66      0.62       996\n           8       0.47      0.46      0.47       986\n           9       0.77      0.74      0.75      1000\n\n    accuracy                           0.50      9816\n   macro avg       0.48      0.50      0.49      9816\nweighted avg       0.48      0.50      0.49      9816\n'}, 21: {'SSE': 23783341043.824547, 'correct_pred': 5146, 'classification_report': '              precision    recall  f1-score   support\n\n           0       0.50      0.47      0.49       971\n           1       0.62      0.80      0.70       963\n           2       0.37      0.41      0.39       986\n           3       0.45      0.42      0.43       973\n           4       0.37      0.34      0.36       991\n           5       0.53      0.64      0.58       979\n           6       0.29      0.15      0.20       971\n           7       0.63      0.64      0.64       996\n           8       0.54      0.59      0.57       986\n           9       0.79      0.78      0.78      1000\n\n    accuracy                           0.52      9816\n   macro avg       0.51      0.52      0.51      9816\nweighted avg       0.51      0.52      0.51      9816\n'}, 26: {'SSE': 22737393544.82862, 'correct_pred': 5328, 'classification_report': '              precision    recall  f1-score   support\n\n           0       0.51      0.49      0.50       971\n           1       0.71      0.79      0.75       963\n           2       0.38      0.39      0.38       986\n           3       0.44      0.46      0.45       973\n           4       0.41      0.42      0.41       991\n           5       0.56      0.68      0.61       979\n           6       0.31      0.17      0.22       971\n           7       0.66      0.65      0.66       996\n           8       0.53      0.59      0.56       986\n           9       0.82      0.78      0.80      1000\n\n    accuracy                           0.54      9816\n   macro avg       0.53      0.54      0.53      9816\nweighted avg       0.53      0.54      0.53      9816\n'}, 31: {'SSE': 21842366257.31934, 'correct_pred': 5435, 'classification_report': '              precision    recall  f1-score   support\n\n           0       0.51      0.51      0.51       971\n           1       0.73      0.80      0.76       963\n           2       0.38      0.40      0.39       986\n           3       0.46      0.48      0.47       973\n           4       0.40      0.40      0.40       991\n           5       0.57      0.67      0.61       979\n           6       0.33      0.15      0.20       971\n           7       0.69      0.70      0.70       996\n           8       0.55      0.62      0.58       986\n           9       0.82      0.79      0.80      1000\n\n    accuracy                           0.55      9816\n   macro avg       0.54      0.55      0.54      9816\nweighted avg       0.54      0.55      0.54      9816\n'}, 36: {'SSE': 21165846766.901886, 'correct_pred': 5518, 'classification_report': '              precision    recall  f1-score   support\n\n           0       0.51      0.55      0.53       971\n           1       0.69      0.80      0.74       963\n           2       0.39      0.46      0.42       986\n           3       0.48      0.49      0.48       973\n           4       0.44      0.41      0.42       991\n           5       0.58      0.67      0.62       979\n           6       0.31      0.17      0.22       971\n           7       0.70      0.65      0.68       996\n           8       0.62      0.60      0.61       986\n           9       0.81      0.81      0.81      1000\n\n    accuracy                           0.56      9816\n   macro avg       0.55      0.56      0.55      9816\nweighted avg       0.55      0.56      0.55      9816\n'}, 41: {'SSE': 20543695636.388428, 'correct_pred': 5550, 'classification_report': '              precision    recall  f1-score   support\n\n           0       0.56      0.53      0.54       971\n           1       0.73      0.78      0.75       963\n           2       0.40      0.49      0.44       986\n           3       0.46      0.48      0.47       973\n           4       0.43      0.39      0.41       991\n           5       0.57      0.71      0.63       979\n           6       0.30      0.17      0.22       971\n           7       0.71      0.69      0.70       996\n           8       0.59      0.61      0.60       986\n           9       0.81      0.80      0.81      1000\n\n    accuracy                           0.57      9816\n   macro avg       0.56      0.56      0.56      9816\nweighted avg       0.56      0.57      0.56      9816\n'}, 46: {'SSE': 19986951480.740067, 'correct_pred': 5698, 'classification_report': '              precision    recall  f1-score   support\n\n           0       0.55      0.55      0.55       971\n           1       0.73      0.79      0.76       963\n           2       0.41      0.49      0.45       986\n           3       0.47      0.51      0.49       973\n           4       0.44      0.41      0.42       991\n           5       0.58      0.70      0.63       979\n           6       0.36      0.19      0.25       971\n           7       0.71      0.75      0.73       996\n           8       0.64      0.62      0.63       986\n           9       0.85      0.80      0.82      1000\n\n    accuracy                           0.58      9816\n   macro avg       0.57      0.58      0.57      9816\nweighted avg       0.57      0.58      0.57      9816\n'}, 51: {'SSE': 19505339936.97023, 'correct_pred': 5693, 'classification_report': '              precision    recall  f1-score   support\n\n           0       0.53      0.58      0.55       971\n           1       0.78      0.78      0.78       963\n           2       0.42      0.48      0.45       986\n           3       0.47      0.51      0.49       973\n           4       0.44      0.41      0.42       991\n           5       0.59      0.73      0.65       979\n           6       0.31      0.17      0.22       971\n           7       0.71      0.69      0.70       996\n           8       0.63      0.61      0.62       986\n           9       0.84      0.84      0.84      1000\n\n    accuracy                           0.58      9816\n   macro avg       0.57      0.58      0.57      9816\nweighted avg       0.57      0.58      0.57      9816\n'}, 56: {'SSE': 19085393480.756634, 'correct_pred': 5745, 'classification_report': '              precision    recall  f1-score   support\n\n           0       0.54      0.57      0.55       971\n           1       0.72      0.81      0.76       963\n           2       0.42      0.47      0.44       986\n           3       0.47      0.51      0.49       973\n           4       0.44      0.42      0.43       991\n           5       0.60      0.70      0.65       979\n           6       0.35      0.19      0.24       971\n           7       0.74      0.76      0.75       996\n           8       0.64      0.59      0.62       986\n           9       0.84      0.82      0.83      1000\n\n    accuracy                           0.59      9816\n   macro avg       0.58      0.58      0.58      9816\nweighted avg       0.58      0.59      0.58      9816\n'}, 61: {'SSE': 18691971201.023617, 'correct_pred': 5882, 'classification_report': '              precision    recall  f1-score   support\n\n           0       0.55      0.58      0.56       971\n           1       0.74      0.85      0.79       963\n           2       0.43      0.49      0.46       986\n           3       0.49      0.47      0.48       973\n           4       0.45      0.44      0.45       991\n           5       0.62      0.74      0.67       979\n           6       0.37      0.21      0.27       971\n           7       0.72      0.76      0.74       996\n           8       0.67      0.61      0.64       986\n           9       0.85      0.84      0.84      1000\n\n    accuracy                           0.60      9816\n   macro avg       0.59      0.60      0.59      9816\nweighted avg       0.59      0.60      0.59      9816\n'}, 66: {'SSE': 18326473084.043724, 'correct_pred': 5903, 'classification_report': '              precision    recall  f1-score   support\n\n           0       0.56      0.57      0.57       971\n           1       0.72      0.86      0.78       963\n           2       0.43      0.50      0.46       986\n           3       0.48      0.49      0.49       973\n           4       0.46      0.43      0.44       991\n           5       0.61      0.75      0.67       979\n           6       0.37      0.20      0.26       971\n           7       0.72      0.80      0.76       996\n           8       0.68      0.59      0.63       986\n           9       0.87      0.82      0.84      1000\n\n    accuracy                           0.60      9816\n   macro avg       0.59      0.60      0.59      9816\nweighted avg       0.59      0.60      0.59      9816\n'}, 71: {'SSE': 18015560565.641396, 'correct_pred': 5846, 'classification_report': '              precision    recall  f1-score   support\n\n           0       0.56      0.55      0.55       971\n           1       0.73      0.85      0.78       963\n           2       0.42      0.50      0.46       986\n           3       0.50      0.51      0.50       973\n           4       0.45      0.39      0.42       991\n           5       0.61      0.74      0.67       979\n           6       0.36      0.20      0.25       971\n           7       0.71      0.79      0.75       996\n           8       0.66      0.62      0.64       986\n           9       0.85      0.81      0.83      1000\n\n    accuracy                           0.60      9816\n   macro avg       0.58      0.60      0.59      9816\nweighted avg       0.58      0.60      0.59      9816\n'}, 76: {'SSE': 17749233501.45924, 'correct_pred': 5900, 'classification_report': '              precision    recall  f1-score   support\n\n           0       0.58      0.58      0.58       971\n           1       0.71      0.87      0.78       963\n           2       0.43      0.47      0.45       986\n           3       0.49      0.48      0.48       973\n           4       0.45      0.42      0.44       991\n           5       0.63      0.75      0.68       979\n           6       0.36      0.23      0.28       971\n           7       0.72      0.79      0.76       996\n           8       0.67      0.60      0.63       986\n           9       0.84      0.82      0.83      1000\n\n    accuracy                           0.60      9816\n   macro avg       0.59      0.60      0.59      9816\nweighted avg       0.59      0.60      0.59      9816\n'}, 81: {'SSE': 17457725522.76751, 'correct_pred': 5936, 'classification_report': '              precision    recall  f1-score   support\n\n           0       0.57      0.58      0.57       971\n           1       0.76      0.85      0.80       963\n           2       0.43      0.48      0.45       986\n           3       0.50      0.52      0.51       973\n           4       0.45      0.41      0.43       991\n           5       0.62      0.72      0.67       979\n           6       0.36      0.23      0.28       971\n           7       0.74      0.79      0.76       996\n           8       0.69      0.62      0.65       986\n           9       0.83      0.84      0.84      1000\n\n    accuracy                           0.60      9816\n   macro avg       0.59      0.60      0.60      9816\nweighted avg       0.59      0.60      0.60      9816\n'}, 86: {'SSE': 17220484206.979885, 'correct_pred': 5922, 'classification_report': '              precision    recall  f1-score   support\n\n           0       0.55      0.57      0.56       971\n           1       0.72      0.87      0.79       963\n           2       0.43      0.50      0.46       986\n           3       0.48      0.50      0.49       973\n           4       0.48      0.44      0.46       991\n           5       0.63      0.72      0.67       979\n           6       0.38      0.21      0.27       971\n           7       0.72      0.79      0.76       996\n           8       0.68      0.61      0.64       986\n           9       0.85      0.81      0.83      1000\n\n    accuracy                           0.60      9816\n   macro avg       0.59      0.60      0.59      9816\nweighted avg       0.59      0.60      0.59      9816\n'}, 91: {'SSE': 17011219002.823446, 'correct_pred': 6007, 'classification_report': '              precision    recall  f1-score   support\n\n           0       0.58      0.59      0.59       971\n           1       0.75      0.88      0.81       963\n           2       0.45      0.47      0.46       986\n           3       0.49      0.47      0.48       973\n           4       0.46      0.45      0.46       991\n           5       0.63      0.74      0.68       979\n           6       0.40      0.24      0.30       971\n           7       0.71      0.81      0.76       996\n           8       0.68      0.63      0.65       986\n           9       0.85      0.82      0.84      1000\n\n    accuracy                           0.61      9816\n   macro avg       0.60      0.61      0.60      9816\nweighted avg       0.60      0.61      0.60      9816\n'}}